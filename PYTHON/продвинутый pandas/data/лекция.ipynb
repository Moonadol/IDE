{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Метод sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Часто бывает так, что таблицу или промежуточный результат операций с ней необходимо отсортировать по какому-то критерию. Например, для отчётности вам необходимо предоставить список проданных объектов недвижимости, отсортированный по возрастанию цены или дате продажи. Рассмотрим основные подходы к решению таких задач.\n",
    "Для сортировки значений в DataFrame по значениям одного или нескольких столбцов используется метод sort_values()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* by — имя или список имён столбцов, по значениям которых производится сортировка.\n",
    "* axis — ось, по которой производится сортировка (0 — строки, 1 — столбцы). По умолчанию сортировка производится по строкам.\n",
    "* ascending — сортировка по возрастанию (от меньшего к большему). По умолчанию параметр выставлен на True, для сортировки по убыванию (от большего к меньшему) необходимо выставить его на False.\n",
    "* ignore_index — создаются ли новые индексы в таблице. По умолчанию выставлен на False и сохраняет индексы изначальной таблицы.\n",
    "* inplace — производится ли замена исходной таблицы на отсортированную. По умолчанию параметр выставлен на False, то есть замены не производится. Чтобы переопределить исходную таблицу на отсортированную, необходимо выставить этот параметр на True."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сортировка по значениям одного столбца\n",
    "Отсортируем таблицу по возрастанию цены объектов недвижимости (Price):\n",
    "\n",
    "melb_df.sort_values(by='Price').head(10)\n",
    "Мы вывели десять строк таблицы, чтобы убедиться в верном порядке сортировки. Также обратите внимание на индексы таблицы — их значения сохранились из исходной таблицы.\n",
    "\n",
    "А теперь отсортируем таблицу по убыванию (от самой последней до самой первой) даты продажи объекта (Date). Для этого выставим параметр ascending на False:\n",
    "\n",
    "melb_df.sort_values(by='Date', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сортировка по значениям нескольких столбцов\n",
    "Для сортировки по значениям нескольких столбцов необходимо передать названия этих столбцов в параметр by в виде списка. При этом важно обращать внимание на порядок следования столбцов.\n",
    "\n",
    "Так, например, отсортируем таблицу сначала по возрастанию расстояния от центра города (Distance), а затем — по возрастанию цены объекта (Price). Для того чтобы вывод был более наглядным, выделим каждую десятую строку из столбцов Distance и Price результирующей таблицы:\n",
    "\n",
    "melb_df.sort_values(by=['Distance', 'Price']).loc[::10, ['Distance', 'Price']]\n",
    "Мы получили таблицу, отсортированную по возрастанию расстояния до центра города. Если встречаются объекты недвижимости, у которых расстояние оказывается одинаковым, то внутри такой группы производится сортировка по цене объекта.\n",
    "\n",
    "Ради интереса попробуйте поменять порядок следования столбцов в параметре by метода sort_values() и сравните результат. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Комбинирование сортировки с фильтрацией\n",
    "А теперь рассмотрим применение сортировки на практике.\n",
    "\n",
    "Предположим, компания McGrath поручила нам восстановить хронологию продаж таунхаусов, у которых площадь участка существенно больше площади здания, чтобы понять, как часто компания справляется с таким сложным видом объектов. Объекты, проданные в один и тот же день, мы бы хотели сортировать по значению коэффициента соотношения площадей. \n",
    "\n",
    "Найдём информацию о таунхаусах (Type), проданных компанией (SellerG) McGrath, у которых коэффициент соотношения площадей здания и участка (AreaRatio) меньше -0.8. Результат отсортируем по дате продажи (Date) в порядке возрастания, а после проведём сортировку по убыванию коэффициента соотношения площадей. Также обновим старые индексы на новые, установив параметр ignore_index на True. Для наглядности результата выберем из таблицы только столбцы Data и AreaRatio:\n",
    "\n",
    "mask1 = melb_df['AreaRatio'] < -0.8\n",
    "mask2 = melb_df['Type'] == 'townhouse'\n",
    "mask3 = melb_df['SellerG'] == 'McGrath'\n",
    "melb_df[mask1 & mask2 & mask3].sort_values(\n",
    "    by=['Date', 'AreaRatio'],\n",
    "    ascending=[True, False],\n",
    "    ignore_index=True\n",
    ").loc[:, ['Date', 'AreaRatio']]\n",
    "Примечание. Старайтесь не сочетать фильтрацию и метод sort_values() с параметром inplace=True, так как в таком случае у вас возникнет предупреждение (warning) SettingWithCopyWarning: melb_df[melb_df['Rooms'] > 5].sort_values(inplace=True, by=['Rooms']):\n",
    "\n",
    "C:\\Users\\Andrey\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311: SettingwithCopyWarning:\n",
    "\n",
    "A value is trying to be set on a copy of a slice from a DataFrame\n",
    "\n",
    "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/ indexing. html#retu rning-a-view-versus-a-copy\n",
    "\n",
    "    return func(*args, **kwargs)\n",
    "Стоит отметить, что это не ошибка и код в таком случае отработает. Однако Pandas предупреждает вас о том, что при использовании такого кода дальнейшие результаты могут быть неожиданными.\n",
    "\n",
    "Это предупреждение предназначено для обозначения операций «цепного присваивания». Это ситуация, когда вы пытаетесь напрямую изменить подмножество исходных данных. В нашем случае мы пытаемся отсортировать данные с заменой (об этом говорит параметр inplace=True) исходной таблицы на отсортированную.\n",
    "\n",
    "Чтобы не возникало подобных конфликтов, необходимо использовать метод copy() для явного создания копии отфильтрованного подмножества исходных данных и работать уже с ней (производить сортировку):\n",
    "\n",
    "filtered = melb_df[melb_df['Rooms'] > 5].copy()\n",
    "\n",
    "filtered.sort_values(inplace=True, by=['Rooms'])\n",
    "\n",
    "filtered.head()\n",
    "Почитать о предупреждении SettingWithCopyWarning можно здесь."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# группировка данных\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Одна из основных задач анализа данных — это группировка данных и сравнение показателей в группах. Например, нам необходимо сравнить средний уровень заработной платы в зависимости от пола/уровня образования. Или же мы хотим проследить, какая группа клиентов приносит нам наибольший доход, чтобы направить своё внимание на эту группу.\n",
    "\n",
    "В некоторых случаях группировки может быть достаточно, чтобы ответить на вопросы бизнеса. В других случаях это может стать первым шагом в более сложном анализе. Так, например, благодаря группировке мы можем выявлять признаки, которые не несут статистической значимости, или признаки, которые вносят наибольший вклад. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод groupby()\n",
    "* by — имя или список имён столбцов, по которым производится группировка.\n",
    "* axis — ось, по которой производится группировка (0 — строки, 1 — столбцы). По умолчанию группировка * производится по строкам.\n",
    "* as_index — добавляется ли дополнительный индекс к таблице. По умолчанию установлен на True."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод groupby() возвращает объект DataFrameGroupBy, который хранит в себе информацию о том, какие строки относятся к определённой группе, и сам по себе не представляет для нас интереса. \n",
    "\n",
    "Однако к этому объекту можно применять уже знакомые нам агрегирующие методы (mean, median, sum и т. д.), чтобы рассчитывать показатели внутри каждой группы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Группировка данных по одному критерию с одной агрегацией\n",
    "Рассмотрим группировку данных на примере нашей таблицы с недвижимостью.\n",
    "\n",
    "Применим агрегирующую функцию среднего к результату работы groupby(). В качестве столбца для группировки возьмём столбец типа объекта недвижимости (Type):\n",
    "\n",
    "melb_df.groupby(by='Type').mean(numeric_only=True)\n",
    "Мы получили таблицу, на пересечении строк и столбцов которой находятся средние значения каждого числового признака в наших данных.\n",
    "\n",
    "Обратите внимание на структуру получившейся таблицы: теперь на месте индексов стоят значения типа объекта недвижимости Type (house, townhouse, unit).\n",
    "\n",
    "Примечание. Если мы хотим видеть тип объекта в качестве отдельного столбца таблицы, мы можем выставить параметр as_index на False\n",
    "Как правило, нам не нужна информация обо всех столбцах, поэтому агрегирующие методы можно применять только к интересующему нас столбцу. Например, давайте сравним средние цены на объекты в зависимости от их типа:\n",
    "\n",
    "melb_df.groupby('Type')['Price'].mean()\n",
    "Примечание. Обратите внимание, что, так как мы считаем только один показатель (среднее) для одного столбца, в результате мы получаем объект Series.\n",
    "\n",
    "Из этой маленькой таблицы видно, что наибольшей средней ценой обладают объекты типа house (дома, коттеджи, виллы). Следовательно, можно сделать вывод, что тип постройки является значимым фактором при определении цены объекта недвижимости.\n",
    "\n",
    "Теперь давайте выясним, какие регионы (Regionname) наиболее удалены от центра Мельбурна.\n",
    "\n",
    "Для этого найдём минимальное значение расстояния от центра города до объекта в зависимости от его региона. Результат отсортируем по убыванию расстояния:\n",
    "\n",
    "melb_df.groupby('Regionname')['Distance'].min().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Группировка данных по одному критерию с несколькими агрегациями\n",
    "Чтобы рассчитать несколько агрегирующих методов, можно воспользоваться методом agg(), который принимает список строк с названиями агрегаций.\n",
    "\n",
    "Давайте построим таблицу для анализа продаж по месяцам. Для этого найдём количество продаж, а также среднее и максимальное значения цен объектов недвижимости (Price), сгруппированных по номеру месяца продажи (MonthSale). Результат отсортируем по количеству продаж в порядке убывания:\n",
    "\n",
    "melb_df.groupby('MonthSale')['Price'].agg(\n",
    "        ['count', 'mean', 'max']\n",
    "    ).sort_values(by='count', ascending=False)\n",
    "    Примечание. Обратите внимание, что, так как мы считаем несколько показателей для одного столбца, в результате мы получаем объект DataFrame.\n",
    "\n",
    "В результате применения метода agg(), в который мы передали список с названиями интересующих нас агрегирующих функций, мы получаем DataFrame со столбцами count, mean и max, где для каждого месяца рассчитаны соответствующие параметры. Результат сортируем по столбцу count.\n",
    "Примечание. Если вам нужна полная информация обо всех основных статистических характеристиках внутри каждой группы, вы можете воспользоваться методом agg(), передав в качестве его параметра строку 'describe':\n",
    "\n",
    "melb_df.groupby('MonthSale')['Price'].agg('describe')\n",
    "    \n",
    "После базовых математических функций наиболее частым агрегированием является подсчёт числа уникальных значений. Так, например, мы можем вычислить число уникальных риелторских компаний в зависимости от региона, чтобы понять, в каких регионах конкуренция на рынке недвижимости меньше. Это можно сделать, передав в параметр метода agg() строку 'nunique'. \n",
    "\n",
    "Более того, метод agg() поддерживает использование и других функций. Передадим дополнительно встроенную функцию set, чтобы получить множество из агентств недвижимости, которые работают в каждом из регионов:\n",
    "\n",
    "melb_df.groupby('Regionname')['SellerG'].agg(\n",
    "                ['nunique', set]\n",
    "    )\n",
    "    Методы группировки по одному признаку позволяют посмотреть на наши данные «в разрезе» группирующего признака и понять их взаимосвязь. Далее мы рассмотрим, как оценивать взаимосвязь между большим количеством признаков."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сводные таблицы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сводные таблицы — это распространённый инструмент для агрегации данных.\n",
    "\n",
    "→ Сводная таблица принимает на вход данные из отдельных столбцов и группирует их. В результате получается новая таблица, которая позволяет увидеть многомерное обобщение данных. Таким образом, благодаря сводным таблицам мы можем оценить зависимость между двумя и более признаками данных.\n",
    "\n",
    "Мы чаще сталкиваемся со сводными таблицами, чем с обычными, в плоском виде, так как сводные таблицы удобнее для анализа и быстрых выводов, а также позволяют увидеть более общие зависимости между признаками, нежели простая группировка данных.\n",
    "\n",
    "Инструмент сводных таблиц также широко популярен среди тех, кто использует Excel или какие-либо BI-системы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Метод groupby как способ построения сводных таблиц\n",
    "На самом деле мы с вами уже строили простейшие одномерные сводные таблицы с помощью метода groupby — мы рассматривали сводную таблицу в контексте группировки по одному признаку. \n",
    "\n",
    "Например, мы уже умеем строить таблицу, которая показывает зависимость медианной цены и площади здания от числа комнат:\n",
    "\n",
    "melb_df.groupby('Rooms')[['Price', 'BuildingArea']].median()\n",
    "Также можно построить таблицу, в которой мы будем учитывать не только число комнат, но и тип здания (Type). Для этого в параметрах метода groupby() укажем список из нескольких интересующих нас столбцов.\n",
    "\n",
    "melb_df.groupby(['Rooms', 'Type'])['Price'].mean()\n",
    "В результате выполнения такого кода мы получаем Series, которая обладает несколькими уровнями индексов: первый уровень — число комнат, второй уровень — тип здания. Такая организация индексов называется иерархической. Вычисление параметра (средней цены) происходит во всех возможных комбинациях признаков.\n",
    "\n",
    "Для того, чтобы финальный результат был представлен в виде сводной таблицы (первый группировочный признак по строкам, а второй — по столбцам), а не в виде Series с иерархическими индексами, к результату чаще всего применяют метод unstack(), который позволяет переопределить вложенный индекс в виде столбцов таблицы:\n",
    "\n",
    "melb_df.groupby(['Rooms', 'Type'])['Price'].mean().unstack()\n",
    "В результате мы получаем сводную таблицу, столбцы в которой представляют типы домов (house, townhouse, unit), строки — число комнат, а на пересечении строк и столбцов находится средняя стоимость объекта с такими показателями.\n",
    "\n",
    "?\n",
    "Какие интересные выводы можно сделать из этой таблицы?\n",
    "\n",
    "Пропуски в сводной таблице (NaN) говорят о том, что в наших данных нет соответствующих комбинаций признаков. Например, у нас нет информации о ценах на таунхаусы, где количество комнат больше пяти.\n",
    "\n",
    "Наибольшей средней стоимостью (2,25 млн. австралийских долларов) обладают объекты типа unit с восемью жилыми комнатами. Наименьшая средняя стоимость — у однокомнатных домов типа unit (чуть меньше 400 тыс. австралийских долларов).\n",
    "\n",
    "Сколько бы комнат ни было в доме, цена на объекты типа unit всегда ниже других (за исключением восьмикомнатных объектов)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Метод pivot_table для построения сводных таблиц\n",
    "На самом деле метод groupby редко используется при двух параметрах, так как для построения сводных таблиц существует специальный и более простой метод — pivot_table().\n",
    "* values — имя столбца, по которому необходимо получить сводные данные, применяя агрегирующую функцию;\n",
    "* index — имя столбца, значения которого станут строками сводной таблицы;\n",
    "* columns — имя столбца, значения которого станут столбцами сводной таблицы;\n",
    "* aggfunc — имя или список имён агрегирующих функций (по умолчанию — подсчёт среднего, 'mean');\n",
    "* fill_value — значение, которым необходимо заполнить пропуски (по умолчанию пропуски не заполняются).\n",
    "Давайте построим ту же самую таблицу, но уже с использованием метода pivot_table. В качестве параметра values укажем столбец Price, в качестве индексов сводной таблицы возьмём Rooms, а в качестве столбцов — Type. Агрегирующую функцию оставим по умолчанию (среднее). Дополнительно заменим пропуски в таблице на значение 0. Финальный результат для наглядности вывода округлим с помощью метода round() до целых.\n",
    "\n",
    "melb_df.pivot_table(\n",
    "        values='Price',\n",
    "        index='Rooms',\n",
    "        columns='Type',\n",
    "        fill_value=0\n",
    "Несложно понять, что метод pivot_table() имеет преимущество перед группировкой по нескольким критериям. Оно заключается в наличии специальных аргументов для строк и столбцов сводной таблицы, благодаря чему уменьшается вероятность запутаться при построении более сложных (многомерных) сводных таблиц, о которых мы поговорим далее.\n",
    "\n",
    "А теперь давайте проанализируем продажи в каждом из регионов в зависимости от того, будний был день или выходной. Для этого построим сводную таблицу, в которой строками будут являться названия регионов (Regionname), а в столбцах будет располагаться наш «признак-мигалка» выходного дня (Weekend), который равен 1, если день был выходным, и 0 — в противном случае. В качестве значений сводной таблицы возьмём количество продаж.\n",
    "\n",
    "melb_df.pivot_table(\n",
    "        values='Price',\n",
    "        index='Regionname',\n",
    "        columns='Weekend',\n",
    "        aggfunc='count'\n",
    "    )\n",
    "Из результирующей таблицы можно сделать два вывода:\n",
    "\n",
    "Число продаж резко возрастает в выходные вне зависимости от региона (приблизительно в 2-3 раза). То есть вероятность того, что дом продадут в выходные, гораздо выше вероятности, что его продадут в будний день.\n",
    "\n",
    "В отдалённых регионах (Victoria) коэффициент роста числа продаж выше, чем в центральных. Если в центральных регионах Metropolitan продажи по выходным в 2-2.5 раза выше, чем по будням, то в регионах Victoria число продаж в выходные вырастает примерно в 3 раза.\n",
    "\n",
    "Такой рост можно даже попытаться объяснить логически: в выходные дни у людей появляется свободное время, чтобы доехать до отдалённых пригородов с целью покупки дома.\n",
    "\n",
    "Разберём ещё один пример: найдём, как зависит средняя и медианная площадь участка (Landsize) от типа объекта (Type) и его региона (Regionname). Чтобы посмотреть несколько статистических параметров, нужно передать в аргумент aggfunc список из агрегирующих функций. Построим такую сводную таблицу, где пропущенные значения заменим на 0:\n",
    "\n",
    "melb_df.pivot_table(\n",
    "        values='Landsize',\n",
    "        index='Regionname',\n",
    "        columns='Type',\n",
    "        aggfunc=['median', 'mean'],\n",
    "        fill_value=0\n",
    "    )\n",
    "Обратите внимание на добавление дополнительных индексов столбцов median и mean. Здесь медианное и среднее значения рассчитаны отдельно для каждой комбинации признаков.\n",
    "\n",
    "Здесь в глаза бросаются объекты типа house в регионах Eastern Victoria и Northern Victoria — в них среднее и медиана отличаются более чем в три раза. Вероятно, это связано с тем, что в этих районах очень большой разброс цен: есть несколько объектов с гигантской площадью, а остальные объекты имеют небольшую площадь. Из-за этого среднее значение искажается, в то время как медиана нечувствительна к такому разбросу и не искажает результат."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Многомерные сводные таблицы\n",
    "До этого мы рассматривали, как некоторый статистический показатель может зависеть от двух признаков. Однако, как уже упоминалось, сводные таблицы позволяют наблюдать зависимость и от большего числа признаков. Такие сводные таблицы называются многомерными. \n",
    "\n",
    "Для того чтобы исследовать зависимость от большего числа признаков, можно передать список признаков в параметр index или параметр columns.\n",
    "\n",
    "Давайте построим таблицу, в которой по индексам будут располагаться признаки метода продажи (Method) и типа объекта (Type), по столбцам — наименование региона (Regionname), а на пересечении строк и столбцов будет стоять медианная цена объекта (Price):\n",
    "\n",
    "melb_df.pivot_table(\n",
    "        values='Price',\n",
    "        index=['Method','Type'],\n",
    "        columns='Regionname',\n",
    "        aggfunc='median',\n",
    "        fill_value=0\n",
    "    )\n",
    "Первым индексом в таблице идёт метод продажи здания, далее для метода указывается тип недвижимости. По столбцам расположены регионы. В ячейках таблицы указана медианная цена для каждой такой комбинации.\n",
    "\n",
    "Такие таблицы уже сложнее читать, однако с помощью них можно более глубоко исследовать закономерности. Например, можно видеть, что вне зависимости от метода продажи и региона цена на объекты типа house практически всегда выше, чем на объекты другого типа."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Доступ к данным в сводной таблице\n",
    "Давайте рассмотрим, что собой представляют столбцы сложной сводной таблицы.\n",
    "\n",
    "Запишем сводную таблицу, которую мы создавали ранее в переменную pivot:\n",
    "\n",
    "pivot = melb_df.pivot_table(\n",
    "        values='Landsize',\n",
    "        index='Regionname',\n",
    "        columns='Type',\n",
    "        aggfunc=['median', 'mean'],\n",
    "        fill_value=0\n",
    "    )\n",
    "    \n",
    "Выведем её столбцы с помощью атрибута columns:\n",
    "\n",
    "pivot.columns\n",
    "В результате мы получаем объект MultiIndex. Этот объект хранит в себе шесть комбинаций пар столбцов (два статистических параметра и три типа здания), то есть есть шесть возможных вариантов обращения к столбцам таблицы.\n",
    "\n",
    "Мультииндексы раскрываются подобно вложенным словарям — по очереди, как матрёшка. Чтобы получить доступ к определённому столбцу, вы должны сначала обратиться к столбцу, который находится уровнем выше.\n",
    "\n",
    "Так, из таблицы pivot мы можем получить средние значения площадей участков для типа здания unit, просто последовательно обратившись по имени столбцов:\n",
    "\n",
    "display(pivot['mean']['unit'])\n",
    "Аналогично производится и фильтрация данных. Например, если нам нужны регионы, в которых средняя площадь здания для домов типа house меньше их медианной площади, то мы можем найти их следующим образом:\n",
    "\n",
    "mask = pivot['mean']['house'] < pivot['median']['house']\n",
    "    filtered_pivot = pivot[mask]\n",
    "    display(filtered_pivot)\n",
    "Чтобы получить индексы отфильтрованной таблицы, можно воспользоваться атрибутом index и обернуть результат в список:\n",
    "\n",
    "print(list(filtered_pivot.index))\n",
    "    # ['Southern Metropolitan', 'Western Metropolitan']\n",
    "    \n",
    "✍ Таким образом, сводные таблицы изначально кажутся сложной структурой, но на самом деле это обычные DataFrame со вложенными индексами строк или столбцов. \n",
    "\n",
    "Умение читать и анализировать сложные сводные таблицы — это важный навык, который помогает проводить углублённый анализ данных.\n",
    "\n",
    "Примечание. На самом деле мультииндексные таблицы можно создавать и вручную. Давайте посмотрим на синтаксис данной конструкции:\n",
    "\n",
    "import numpy as np\n",
    "mser = pd.Series(\n",
    "        np.random.rand(8),\n",
    "        index=[['white','white','white','blue','blue','red','red','red'], \n",
    "               ['up','down','right','up','down','up','down','left']])\n",
    "    display(mser)\n",
    "В данном примере мы создаём объект Series со вложенными индексами. Мы передаём в качестве индексов Series вложенный список, где первый список задаёт внешний уровень вложенности, а второй список — внутренний уровень вложенности. Значения Series — случайные числа от 0 до 1, сгенерированные функцией np.random.rand() (ваши значения могут отличаться).\n",
    "\n",
    "Если посмотреть на индексы Series, можно увидеть, что они являются мультииндексами:\n",
    "\n",
    "print(mser.index)\n",
    "Аналогично создаются DataFrame со вложенными признаками (вложенными столбцами) — для этого вложенный список передаётся в параметр columns при инициализации таблицы:\n",
    "\n",
    "mframe = pd.DataFrame(\n",
    "        np.random.randn(16).reshape(4,4),\n",
    "        index=[['white','white','red','red'], ['up','down','up','down']],\n",
    "        columns=[['pen','pen','paper','paper'],[1,2,1,2]]\n",
    "    )\n",
    "    display(mframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Объединение DataFrame: знакомимся с новыми данными"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На практике источники данных редко ограничиваются одной таблицей. Например, если мы работаем с базой данных, то данные в ней могут быть представлены в виде нескольких десятков таблиц, каждая из которых несёт отдельную информацию. Если вы делаете выгрузку из базы напрямую, не объединяя таблицы в единую структуру средствами SQL, вам необходимо знать, как работать с такими таблицами средствами Pandas. \n",
    "\n",
    "С какими данными мы работаем?\n",
    "\n",
    "В этой части модуля мы будем работать с популярным датасетом MovieLens, в котором собраны логи некоторой рекомендательной системы фильмов.\n",
    "Наши данные представляют собой четыре таблицы:\n",
    "\n",
    "ratings1 и ratings2 — таблицы с данными о выставленных пользователями оценках фильмов. Они имеют одинаковую структуру и типы данных — на самом деле это две части одной таблицы с оценками фильмов.\n",
    "userId — уникальный идентификатор пользователя, который выставил оценку;\n",
    "movieId — уникальный идентификатор фильма;\n",
    "rating — рейтинг фильма.\n",
    "dates — таблица с датами выставления всех оценок.\n",
    "date — дата и время выставления оценки фильму.\n",
    "movies — таблица с информацией о фильмах.\n",
    "movieId — уникальный идентификатор фильма;\n",
    "title — название фильма и год его выхода;\n",
    "genres — жанры фильма.\n",
    "Итак, представим, что нам надо получить единую таблицу, в которой будут собраны рейтинги, даты выставления рейтингов, а также информация о фильмах. Вот как мы будем действовать:\n",
    "\n",
    "Склеим таблицы ratings1 и ratings2 в единую структуру.\n",
    "\n",
    "К полученной таблице с рейтингами подсоединим столбец с датой проставления рейтинга, склеив столбцы таблиц между собой.\n",
    "\n",
    "Присоединим к нашей таблице информацию о названиях и жанрах фильмов.\n",
    "Конечно, здорово, если все необходимые данные лежат в одной таблице, но на практике такое случается редко по двум объективным причинам:\n",
    "1. Часто данные формируются несколькими независимыми процессами, каждый из которых хранит данные в своей таблице.\n",
    "\n",
    "Например, данные для отчёта по продажам могут состоять из списка банковских транзакций, курсов валют от Центробанка и планов отдела продаж из внутренней CRM. Все эти три таблицы, скорее всего, будут формироваться независимыми друг от друга системами. Объединять их в один отчёт придётся вам.\n",
    "2. Хранить все данные в одной таблице часто очень накладно для ёмкости диска.\n",
    "\n",
    "Например, названия фильмов в наших данных хранятся в отдельной небольшой таблице. А в логах, которые могут растягиваться на многие миллионы строк, вместо названия фильма стоит его идентификатор. Числовой идентификатор фильма занимает на диске гораздо меньше места, чем длинное название, поэтому логи с идентификаторами будут занимать гораздо меньше места, чем единая таблица с названиями."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следуя нашему плану объединения таблиц, первым делом мы должны склеить таблицы ratings1 и ratings2 по строкам.\n",
    "\n",
    "Для этого воспользуемся встроенной функцией Pandas concat(), которая позволяет склеивать (конкатенировать) таблицы как по строкам, так и по столбцам.\n",
    "* objs — список объектов DataFrame ([df1, df2,…]), которые должны быть сконкатенированы;\n",
    "* axis — ось определяет направление конкатенации: 0 — конкатенация по строкам (по умолчанию), 1 — конкатенация по столбцам;\n",
    "* join — либо inner (пересечение), либо outer (объединение); рассмотрим этот момент немного позже;\n",
    "* ignore_index — по умолчанию установлено значение False, которое позволяет значениям индекса оставаться такими, какими они были в исходных данных. Если установлено значение True, параметр будет игнорировать исходные значения и повторно назначать значения индекса в последовательном порядке.\n",
    "Для корректной конкатенации по строкам объединяемые таблицы должны иметь одинаковую структуру — идентичное число и имена столбцов.\n",
    "\n",
    "Итак, давайте склеим  ratings1 и ratings2 по строкам, так как они имеют одинаковую структуру столбцов. Для этого передадим их списком в функцию concat(). Помним, что параметр axis по умолчанию равен 0, объединение происходит по строкам, поэтому не трогаем его. \n",
    "\n",
    "Примечание. Обратите внимание, что concat является функцией библиотеки, а не методом DataFrame. Поэтому её вызов осуществляется как pd.concat(...).\n",
    "\n",
    "ratings = pd.concat([ratings1, ratings2])\n",
    "display(ratings)\n",
    "В результате мы увеличили первую таблицу, добавив снизу строки второй таблицы.\n",
    "\n",
    "На первый взгляд может показаться, что всё прошло успешно, однако если мы посмотрим на индексы последних строк таблицы, то увидим, что их нумерация не совпадает с количеством строк. Это может привести к некорректному объединению таблиц по ключевым столбцам на следующем этапе решения нашей задачи.\n",
    "\n",
    "Это связано с тем, что по умолчанию concat сохраняет первоначальные индексы объединяемых таблиц, а обе наши таблицы индексировались, начиная от 0. Чтобы создать новые индексы, нужно выставить параметр ignore_index на True:\n",
    "\n",
    "ratings = pd.concat(\n",
    "    [ratings1, ratings2],\n",
    "    ignore_index=True\n",
    ")\n",
    "display(ratings)\n",
    "Казалось бы, совсем другое дело! Но это ещё не всё. Давайте узнаем количество строк в таблицах ratings и dates, ведь нам предстоит вертикально склеить их между собой:\n",
    "\n",
    "print('Число строк в таблице ratings: ', ratings.shape[0])\n",
    "print('Число строк в таблице dates: ', dates.shape[0])\n",
    "print(ratings.shape[0] == dates.shape[0])\n",
    "\n",
    " Число строк в таблице ratings: 100837\n",
    " Число строк в таблице dates: 100836\n",
    " False\n",
    "?\n",
    "Размерность таблиц разная — как такое могло произойти?\n",
    "\n",
    "На самом деле очень просто: при выгрузке данных информация об оценках какого-то  пользователя попала в обе таблицы (ratings1 и ratings2). В результате конкатенации случилось дублирование строк. В данном примере их легко найти — выведем последнюю строку таблицы ratings1 и первую строку таблицы ratings2:\n",
    "\n",
    "display(ratings1.tail(1))\n",
    "display(ratings2.head(1))\n",
    "Чтобы очистить таблицу от дублей, мы можем воспользоваться методом DataFrame drop_duplicates(), который удаляет повторяющиеся строки в таблице. Не забываем обновить индексы после удаления дублей, выставив параметр ignore_index в методе drop_duplicates() на значение True:\n",
    "\n",
    "ratings = ratings.drop_duplicates(ignore_index=True)\n",
    "print('Число строк в таблице ratings: ', ratings.shape[0])\n",
    "# Число строк в таблице ratings: 100836\n",
    "Наконец, мы можем добавить к нашей таблице с оценками даты их выставления. Для этого конкатенируем таблицы ratings и dates по столбцам:\n",
    "\n",
    "ratings_dates = pd.concat([ratings, dates], axis=1)\n",
    "display(ratings_dates.tail(7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Объединение DataFrame: join, merge\n",
    "У таблиц ratings и movies есть общий столбец movieId, который каждому фильму из таблицы movies ставит в соответствие поставленные ему оценки из таблицы ratings. Мы хотим объединить их в единую структуру согласно этому соответствию. Объединения такого рода часто называют объединением по ключевому столбцу.\n",
    "\n",
    "→ Однако прежде чем мы перейдём к дальнейшей работе с нашими таблицами о фильмах, мы должны рассмотреть основные типы объединения таблиц.\n",
    "## Типы объединений\n",
    "Типы объединений в Pandas тесно связаны с операцией join из SQL, которую мы будем рассматривать в курсе в дальнейшем.\n",
    "\n",
    "Они представлены на схеме ниже в виде кругов Эйлера. \n",
    "Прежде чем мы перейдём к дальнейшей работе с таблицами о фильмах, рассмотрим два основных типа объединения таблиц:\n",
    "1) inner (внутреннее)\n",
    "\n",
    "При использовании такого типа объединения в результирующей таблице остаются только те записи, которые есть в обеих таблицах.\n",
    "Пересечение (intersection) множеств А и В.\n",
    "\n",
    "Строки, для которых совпадение не было найдено, удаляются.\n",
    "2) outer (внешнее)\n",
    "\n",
    "Данный тип делится на три подтипа:\n",
    "\n",
    "* full — используется как outer по умолчанию, объединяет все варианты в обеих таблицах.\n",
    "Объединение (union) множеств А и В.\n",
    "\n",
    "* left — для всех записей из «левой» таблицы (например, ratings) ведётся поиск соответствий в «правой» (например, movies). В результирующей таблице останутся только те значения, которым были найдены соответствия, то есть только значения из ratings.\n",
    "Вычитание (difference) множества B из результата объединения (union) множеств А и В.\n",
    "\n",
    "* right — аналогично предыдущему, но остаются значения только из «правой» таблицы. \n",
    "Вычитание (difference) множества А из результата объединения (union) множеств А и В.\n",
    "Во всех трёх случаях, если совпадений между таблицами не найдено, на этом месте ставится пропуск (NaN).\n",
    "## Метод объединения join\n",
    "Для объединения двух таблиц по индексам используется метод DataFrame join(). Однако данный метод можно применить и для того, чтобы объединить таблицы по ключевому столбцу (в нашем случае это movieId).\n",
    "* other — таблица, которую мы присоединяем. При объединении она является «правой», а исходная таблица, от имени которой вызывается метод, является «левой».\n",
    "* how — параметр типа объединения. Он может принимать значения 'inner', 'left' (left outer), 'right' (right * outer), и 'outer' (full outer). По умолчанию параметр установлен на 'left'.\n",
    "* on — параметр, который определяет, по какому столбцу в «левой» таблице происходит объединение по индексам из «правой».\n",
    "* lsuffix и rsuffix — дополнения (суффиксы) к названиям одноимённых столбцов в «левой» и «правой» таблицах.\n",
    "Если использовать метод join() «в лоб» (без указания ключевого столбца), то объединение произойдёт, как и задумано — по индексам двух таблиц согласно установленному типу объединения.\n",
    "\n",
    "Проверим это, объединив таблицы типом left. Так как в наших таблицах есть одноимённые столбцы, установим один из суффиксов, чтобы избежать ошибки:\n",
    "\n",
    "joined_false = ratings_dates.join(\n",
    "    movies,\n",
    "    rsuffix='_right',\n",
    "    how='left'\n",
    ")\n",
    "display(joined_false)\n",
    "При объединении таблиц по индексам в результирующую таблицу попали все строки из «левой» таблицы, а недостающие строки из «правой» были заполнены пропусками. Так работает тип объединения left.\n",
    "\n",
    "Попробуйте изменить тип объединения, чтобы посмотреть на разницу результирующих таблиц.\n",
    "\n",
    "Обратите внимание, что в данном случае у нас получилось два столбца, соответствующих идентификатору фильма: один — из «левой» таблицы (movieId), а другой — из «правой» (movieId_right).\n",
    "\n",
    "Однако это не тот результат, который мы хотели, ведь мы не получили соответствия фильмов и их рейтингов. Чтобы совместить таблицы по ключевому столбцу с помощью метода join(), необходимо использовать ключевой столбец в «правой» таблице в качестве индекса. Это можно сделать с помощью метода set_index(). Также необходимо указать название ключа в параметре on.\n",
    "\n",
    "joined = ratings_dates.join(\n",
    "    movies.set_index('movieId'),\n",
    "    on='movieId',\n",
    "    how='left'\n",
    ")\n",
    "display(joined.head())\n",
    "В результате такого объединения для каждого идентификатора фильма movieId в таблице ratings_dates найден совпадающий с ним идентификатор movieId в таблице movies и присоединена информация о самом фильме (title и genres). Это как раз то, что нам нужно.\n",
    "\n",
    "Обратите внимание, что в результате такого объединения остался лишь один столбец movieId.\n",
    "\n",
    "Примечание. Join() также можно использовать с параметром how='outer'.\n",
    "## Метод объединения merge\n",
    "Аналогично предыдущему, метод merge() предназначен для слияния двух таблиц по ключевым столбцам или по индексам. Однако, в отличие от join(), метод merge() предлагает более гибкий способ управления объединением, благодаря чему является более популярным.\n",
    "* right — присоединяемая таблица. По умолчанию она является «правой».\n",
    "* how — параметр типа объединения. По умолчанию принимает значение 'inner'.\n",
    "* on — параметр, который определяет, по какому столбцу происходит объединение. Определяется автоматически, но рекомендуется указывать вручную.\n",
    "* left_on — если названия столбцов в «левой» и «правой» таблицах не совпадают, то данный параметр отвечает за наименования ключевого столбца исходной таблицы.\n",
    "* right_on — аналогично предыдущему, параметр отвечает за наименование ключевого столбца присоединяемой таблицы\n",
    "→ Метод merge() в первую очередь предназначен для слияния таблиц по заданным ключам, поэтому он не требует установки ключевых столбцов в качестве индекса присоединяемой таблицы. Кроме того, данный метод позволяет объединять даже таблицы с разноимёнными ключами. Таким образом, merge() проще в использовании и более многофункционален, чем схожие методы.\n",
    "\n",
    "Посмотрим на метод merge() в действии. Произведём слияние наших таблиц и получим ту же таблицу, что и ранее:\n",
    "\n",
    "merged = ratings_dates.merge(\n",
    "    movies,\n",
    "    on='movieId',\n",
    "    how='left'\n",
    ")\n",
    "display(merged.head())\n",
    "Проверим, что число строк в таблице ratings_dates совпадает с числом строк в результирующей таблице merged:\n",
    "\n",
    "print('Число строк в таблице ratings_dates: ', ratings_dates.shape[0])\n",
    "print('Число строк в таблице merged: ', merged.shape[0])\n",
    "print(ratings_dates.shape[0] == merged.shape[0])\n",
    "\n",
    " Число строк в таблице ratings_dates: 100836\n",
    " Число строк в таблице merged: 100836\n",
    " True\n",
    "Всё прошло успешно: для каждой оценки пользователя мы нашли информацию о фильме, которому она была выставлена.\n",
    "## Особенности использования merge()\n",
    "Возникает вопрос: почему мы выбрали тип объединения left, а не full, например?\n",
    "\n",
    "Найти ответ нам поможет пример. Объединим ratings_dates с movies по ключевому столбцу movieId, но с параметром how='outer' (full outer) и выведем размер таблицы, а также её «хвост»:\n",
    "\n",
    "merged2 = ratings_dates.merge(\n",
    "    movies,\n",
    "    on='movieId',\n",
    "    how='outer'\n",
    ")\n",
    "print('Число строк в таблице merged2: ', merged2.shape[0])\n",
    "display(merged2.tail())\n",
    "\n",
    " Число строк в таблице merged: 100854\n",
    " Результирующее число строк в таблице увеличилось. Но за счёт чего?\n",
    "\n",
    "Оказывается, в таблице movies содержались фильмы, которым ещё не были выставлены оценки. В результате объединения типом full outer информация о фильмах перенеслась из таблицы movies в результирующую таблицу. Однако, поскольку оценки фильмам ещё не были выставлены, соответствующие столбцы таблицы ratings_dates заполнились пропусками (NaN). Такие фильмы были записаны в конец таблицы.\n",
    "\n",
    "Важно! Учитывайте такие нюансы при работе с несколькими таблицами и всегда проверяйте результат объединения.\n",
    "\n",
    "→ Метод merge() с внешним (outer) типом объединения может использоваться как аналог метода concat() при объединении таблиц с одинаковой структурой (одинаковые количество и названия столбцов) по строкам. В таком случае все одноимённые столбцы таблиц будут считаться ключевыми.\n",
    "\n",
    "Рассмотрим пример: объединим таблицы ratings1 и ratings2, как мы уже делали раньше, но теперь используем метод merge():\n",
    "\n",
    "merge_ratings = ratings1.merge(ratings2, how='outer')\n",
    "print('Число строк в таблице merge_ratings: ', merge_ratings.shape[0])\n",
    "display(merge_ratings)\n",
    " Число строк в таблице merge_ratings: 100836\n",
    "Обратите внимание, что при использовании метода merge() для склейки двух таблиц у нас автоматически пропали дубликаты, которые мы видели при использовании метода concat(). Это особенность метода merge() — автоматическое удаление дублей.\n",
    "## Какой метод объединения использовать?\n",
    "Итак, мы рассмотрели три основных метода объединения таблиц: concat(), join() и merge(). Давайте структурируем материал, изложенный ранее, в виде небольшой блок-схемы, которая поможет вам определить, какой метод является предпочтительным при объединении таблиц.!![alt text](image.png)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
